#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§© ARQ V2.0 ä¸“æ³¨æ¨ç†ä¸åˆè§„å†…æ ¸ (Enhanced Reasoning & Compliance Kernel V2.0)
Attentive Reasoning Queries & Compliance Kernel V2.0

å®ç°å¢å¼ºçš„ç»“æ„åŒ–æ¨ç†ç³»ç»Ÿï¼Œè§£å†³LLMé•¿å¯¹è¯ä¸­çš„"é—å¿˜"å’Œ"è§„åˆ™åç¦»"é—®é¢˜ã€‚
ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
"""

import os
import sys
import json
import asyncio
import logging
import hashlib
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from datetime import datetime
from collections import defaultdict, deque
from abc import ABC, abstractmethod
import enum

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

logger = logging.getLogger(__name__)

class ComplianceLevel(enum.Enum):
    """åˆè§„çº§åˆ«"""
    STRICT = "strict"
    MODERATE = "moderate"
    RELAXED = "relaxed"

class ReasoningMode(enum.Enum):
    """æ¨ç†æ¨¡å¼"""
    STRUCTURED = "structured"
    CREATIVE = "creative"
    ANALYTICAL = "analytical"
    CRITICAL = "critical"

@dataclass
class ComplianceRule:
    """åˆè§„è§„åˆ™"""
    rule_id: str
    rule_name: str
    rule_type: str
    description: str
    priority: int
    conditions: List[str]
    actions: List[str]
    exceptions: List[str] = field(default_factory=list)
    enabled: bool = True
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥éª¤"""
    step_id: str
    step_type: str
    content: str
    confidence: float
    evidence: List[str] = field(default_factory=list)
    assumptions: List[str] = field(default_factory=list)
    conclusions: List[str] = field(default_factory=list)
    next_steps: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ReasoningChain:
    """æ¨ç†é“¾"""
    chain_id: str
    problem_statement: str
    reasoning_mode: ReasoningMode
    compliance_level: ComplianceLevel
    steps: List[ReasoningStep]
    final_conclusion: str
    confidence_score: float
    compliance_score: float
    validation_results: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)

class QuantumComplianceRules:
    """é‡å­åˆè§„è§„åˆ™ç³»ç»Ÿ"""
    
    def __init__(self, rules_path: Optional[str] = None):
        self.rules_path = rules_path or Path.cwd() / ".iflow" / "rules"
        self.rules_path.mkdir(parents=True, exist_ok=True)
        
        self.rules = {}
        self.rule_categories = defaultdict(list)
        self.compliance_matrix = {}
        
        self._load_default_rules()
        self._load_custom_rules()
    
    def add_rule(self, rule: ComplianceRule):
        """æ·»åŠ è§„åˆ™"""
        self.rules[rule.rule_id] = rule
        self.rule_categories[rule.rule_type].append(rule.rule_id)
        self._update_compliance_matrix()
        self._save_rules()
    
    def check_compliance(self, content: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ£€æŸ¥åˆè§„æ€§"""
        context = context or {}
        violations = []
        warnings = []
        suggestions = []
        
        for rule_id, rule in self.rules.items():
            if not rule.enabled:
                continue
            
            # æ£€æŸ¥è§„åˆ™æ¡ä»¶
            if self._evaluate_conditions(rule.conditions, content, context):
                # æ£€æŸ¥ä¾‹å¤–æƒ…å†µ
                if not self._evaluate_exceptions(rule.exceptions, content, context):
                    violation = {
                        'rule_id': rule_id,
                        'rule_name': rule.rule_name,
                        'description': rule.description,
                        'priority': rule.priority,
                        'suggested_actions': rule.actions
                    }
                    
                    if rule.priority >= 8:
                        violations.append(violation)
                    elif rule.priority >= 5:
                        warnings.append(violation)
                    else:
                        suggestions.append(violation)
        
        return {
            'compliant': len(violations) == 0,
            'violations': violations,
            'warnings': warnings,
            'suggestions': suggestions,
            'compliance_score': self._calculate_compliance_score(len(violations), len(warnings))
        }
    
    def get_relevant_rules(self, context: Dict[str, Any]) -> List[ComplianceRule]:
        """è·å–ç›¸å…³è§„åˆ™"""
        relevant_rules = []
        
        for rule in self.rules.values():
            if not rule.enabled:
                continue
            
            # åŸºäºä¸Šä¸‹æ–‡åŒ¹é…è§„åˆ™
            if self._is_rule_relevant(rule, context):
                relevant_rules.append(rule)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        relevant_rules.sort(key=lambda r: r.priority, reverse=True)
        return relevant_rules
    
    def _load_default_rules(self):
        """åŠ è½½é»˜è®¤è§„åˆ™"""
        default_rules = [
            ComplianceRule(
                rule_id="no_harmful_content",
                rule_name="æ— æœ‰å®³å†…å®¹",
                rule_type="safety",
                description="ä¸å¾—ç”Ÿæˆä»»ä½•æœ‰å®³ã€å±é™©æˆ–éæ³•çš„å†…å®¹",
                priority=10,
                conditions=["harmful_keywords", "illegal_activities"],
                actions=["refuse_request", "suggest_alternatives"]
            ),
            ComplianceRule(
                rule_id="accuracy_required",
                rule_name="å‡†ç¡®æ€§è¦æ±‚",
                rule_type="quality",
                description="æ‰€æœ‰ä¿¡æ¯å¿…é¡»å‡†ç¡®å¯é ï¼Œä¸å¾—ä¼ æ’­è™šå‡ä¿¡æ¯",
                priority=9,
                conditions=["factual_claims", "statistics", "technical_specifications"],
                actions=["verify_facts", "cite_sources", "express_uncertainty"]
            ),
            ComplianceRule(
                rule_id="privacy_protection",
                rule_name="éšç§ä¿æŠ¤",
                rule_type="privacy",
                description="ä¿æŠ¤ç”¨æˆ·éšç§ï¼Œä¸å¾—æ³„éœ²ä¸ªäººä¿¡æ¯",
                priority=10,
                conditions=["personal_data", "identifyingInformation"],
                actions=["anonymize_data", "refuse_share", "explain_limits"]
            ),
            ComplianceRule(
                rule_id="ethical_considerations",
                rule_name="ä¼¦ç†è€ƒè™‘",
                rule_type="ethics",
                description="è€ƒè™‘ä¼¦ç†å½±å“ï¼Œé¿å…åè§å’Œæ­§è§†",
                priority=8,
                conditions=["demographic_groups", "sensitive_topics", "biases"],
                actions=["ensure_fairness", "provide_balance", "acknowledge_complexity"]
            ),
            ComplianceRule(
                rule_id="code_quality",
                rule_name="ä»£ç è´¨é‡",
                rule_type="technical",
                description="ç”Ÿæˆé«˜è´¨é‡ã€å®‰å…¨ã€å¯ç»´æŠ¤çš„ä»£ç ",
                priority=7,
                conditions=["code_generation", "security_practices", "performance"],
                actions=["follow_best_practices", "add_comments", "include_error_handling"]
            )
        ]
        
        for rule in default_rules:
            self.rules[rule.rule_id] = rule
            self.rule_categories[rule.rule_type].append(rule.rule_id)
    
    def _load_custom_rules(self):
        """åŠ è½½è‡ªå®šä¹‰è§„åˆ™"""
        try:
            rules_file = self.rules_path / "custom_rules.json"
            if rules_file.exists():
                with open(rules_file, 'r', encoding='utf-8') as f:
                    custom_rules_data = json.load(f)
                    
                    for rule_data in custom_rules_data.get('rules', []):
                        rule = ComplianceRule(**rule_data)
                        self.rules[rule.rule_id] = rule
                        self.rule_categories[rule.rule_type].append(rule.rule_id)
                        
        except Exception as e:
            logger.error(f"åŠ è½½è‡ªå®šä¹‰è§„åˆ™å¤±è´¥: {e}")
    
    def _save_rules(self):
        """ä¿å­˜è§„åˆ™"""
        try:
            rules_file = self.rules_path / "custom_rules.json"
            custom_rules = []
            
            for rule in self.rules.values():
                rule_dict = {
                    'rule_id': rule.rule_id,
                    'rule_name': rule.rule_name,
                    'rule_type': rule.rule_type,
                    'description': rule.description,
                    'priority': rule.priority,
                    'conditions': rule.conditions,
                    'actions': rule.actions,
                    'exceptions': rule.exceptions,
                    'enabled': rule.enabled,
                    'metadata': rule.metadata
                }
                custom_rules.append(rule_dict)
            
            with open(rules_file, 'w', encoding='utf-8') as f:
                json.dump({'rules': custom_rules}, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"ä¿å­˜è§„åˆ™å¤±è´¥: {e}")
    
    def _evaluate_conditions(self, conditions: List[str], content: str, context: Dict[str, Any]) -> bool:
        """è¯„ä¼°æ¡ä»¶"""
        for condition in conditions:
            if self._evaluate_condition(condition, content, context):
                return True
        return False
    
    def _evaluate_condition(self, condition: str, content: str, context: Dict[str, Any]) -> bool:
        """è¯„ä¼°å•ä¸ªæ¡ä»¶"""
        content_lower = content.lower()
        
        # å…³é”®è¯åŒ¹é…
        if condition == "harmful_keywords":
            harmful_keywords = ['hack', 'exploit', 'malware', 'virus', 'attack', 'weapon']
            return any(keyword in content_lower for keyword in harmful_keywords)
        
        elif condition == "illegal_activities":
            illegal_keywords = ['illegal', 'crime', 'fraud', 'theft', 'drugs', 'violence']
            return any(keyword in content_lower for keyword in illegal_keywords)
        
        elif condition == "factual_claims":
            # æ£€æµ‹äº‹å®æ€§å£°æ˜
            patterns = [r'\b(is|are|was|were)\b', r'\d+%?', r'\$[\d,]+']
            return any(re.search(pattern, content) for pattern in patterns)
        
        elif condition == "personal_data":
            personal_patterns = [r'\b\d{3}-\d{2}-\d{4}\b', r'\b\d{11}\b', r'\w+@\w+\.\w+']
            return any(re.search(pattern, content) for pattern in personal_patterns)
        
        # å…¶ä»–æ¡ä»¶è¯„ä¼°...
        
        return False
    
    def _evaluate_exceptions(self, exceptions: List[str], content: str, context: Dict[str, Any]) -> bool:
        """è¯„ä¼°ä¾‹å¤–æƒ…å†µ"""
        for exception in exceptions:
            if self._evaluate_condition(exception, content, context):
                return True
        return False
    
    def _is_rule_relevant(self, rule: ComplianceRule, context: Dict[str, Any]) -> bool:
        """åˆ¤æ–­è§„åˆ™æ˜¯å¦ç›¸å…³"""
        # åŸºäºä¸Šä¸‹æ–‡åˆ¤æ–­è§„åˆ™ç›¸å…³æ€§
        if 'task_type' in context:
            if rule.rule_type == 'safety' and context['task_type'] in ['coding', 'writing']:
                return True
            elif rule.rule_type == 'technical' and context['task_type'] == 'coding':
                return True
            elif rule.rule_type == 'privacy' and 'personal_data' in context:
                return True
        
        return True  # é»˜è®¤ç›¸å…³
    
    def _calculate_compliance_score(self, violations: int, warnings: int) -> float:
        """è®¡ç®—åˆè§„åˆ†æ•°"""
        base_score = 100.0
        violation_penalty = violations * 20
        warning_penalty = warnings * 5
        
        return max(0.0, base_score - violation_penalty - warning_penalty)
    
    def _update_compliance_matrix(self):
        """æ›´æ–°åˆè§„çŸ©é˜µ"""
        # æ›´æ–°è§„åˆ™é—´çš„ä¾èµ–å…³ç³»å’Œå†²çªæ£€æµ‹
        self.compliance_matrix = {}
        
        for rule_id, rule in self.rules.items():
            self.compliance_matrix[rule_id] = {
                'dependencies': [],
                'conflicts': []
            }

class AdvancedReasoningTemplates:
    """é«˜çº§æ¨ç†æ¨¡æ¿"""
    
    def __init__(self):
        self.templates = {}
        self._load_templates()
    
    def get_template(self, reasoning_mode: ReasoningMode, problem_type: str) -> Dict[str, Any]:
        """è·å–æ¨ç†æ¨¡æ¿"""
        template_key = f"{reasoning_mode.value}_{problem_type}"
        return self.templates.get(template_key, self._get_default_template())
    
    def _load_templates(self):
        """åŠ è½½æ¨ç†æ¨¡æ¿"""
        # ç»“æ„åŒ–æ¨ç†æ¨¡æ¿
        self.templates["structured_analytical"] = {
            'steps': [
                'problem_identification',
                'information_gathering',
                'hypothesis_formation',
                'evidence_evaluation',
                'logical_deduction',
                'conclusion_validation'
            ],
            'prompts': {
                'problem_identification': "æ˜ç¡®é—®é¢˜çš„æ ¸å¿ƒç›®æ ‡å’Œçº¦æŸæ¡ä»¶",
                'information_gathering': "æ”¶é›†æ‰€æœ‰ç›¸å…³ä¿¡æ¯å’Œæ•°æ®",
                'hypothesis_formation': "åŸºäºä¿¡æ¯å½¢æˆåˆæ­¥å‡è®¾",
                'evidence_evaluation': "è¯„ä¼°è¯æ®æ”¯æŒå‡è®¾çš„ç¨‹åº¦",
                'logical_deduction': "è¿›è¡Œé€»è¾‘æ¨ç†å¾—å‡ºç»“è®º",
                'conclusion_validation': "éªŒè¯ç»“è®ºçš„åˆç†æ€§å’Œå¯é æ€§"
            }
        }
        
        # åˆ›æ–°æ¨ç†æ¨¡æ¿
        self.templates["creative_design"] = {
            'steps': [
                'requirement_analysis',
                'ideation_brainstorm',
                'concept_development',
                'feasibility_assessment',
                'prototype_design',
                'iteration_refinement'
            ],
            'prompts': {
                'requirement_analysis': "æ·±å…¥åˆ†æç”¨æˆ·éœ€æ±‚å’Œçº¦æŸæ¡ä»¶",
                'ideation_brainstorm': "è¿›è¡Œåˆ›é€ æ€§æ€ç»´å’Œå¤´è„‘é£æš´",
                'concept_development': "å‘å±•å…·ä½“çš„æ¦‚å¿µå’Œæ–¹æ¡ˆ",
                'feasibility_assessment': "è¯„ä¼°æŠ€æœ¯å¯è¡Œæ€§å’Œèµ„æºéœ€æ±‚",
                'prototype_design': "è®¾è®¡åŸå‹å’ŒéªŒè¯æ–¹æ¡ˆ",
                'iteration_refinement': "åŸºäºåé¦ˆè¿­ä»£æ”¹è¿›æ–¹æ¡ˆ"
            }
        }
        
        # æ‰¹åˆ¤æ€§æ€ç»´æ¨¡æ¿
        self.templates["critical_evaluation"] = {
            'steps': [
                'claim_identification',
                'evidence_examination',
                'bias_detection',
                'logical_analysis',
                'alternative_consideration',
                'judgment_formation'
            ],
            'prompts': {
                'claim_identification': "è¯†åˆ«éœ€è¦è¯„ä¼°çš„æ ¸å¿ƒä¸»å¼ ",
                'evidence_examination': "ä»”ç»†æ£€æŸ¥æ”¯æŒè¯æ®çš„è´¨é‡å’Œç›¸å…³æ€§",
                'bias_detection': "æ£€æµ‹æ½œåœ¨çš„åè§å’Œå‡è®¾",
                'logical_analysis': "åˆ†æè®ºè¯çš„é€»è¾‘ç»“æ„",
                'alternative_consideration': "è€ƒè™‘æ›¿ä»£è§‚ç‚¹å’Œè§£é‡Š",
                'judgment_formation': "åŸºäºåˆ†æå½¢æˆåˆ¤æ–­"
            }
        }
    
    def _get_default_template(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤æ¨¡æ¿"""
        return {
            'steps': ['understand', 'analyze', 'solve', 'verify'],
            'prompts': {
                'understand': "ç†è§£é—®é¢˜çš„æœ¬è´¨",
                'analyze': "åˆ†æé—®é¢˜çš„å…³é”®è¦ç´ ",
                'solve': "å¯»æ‰¾è§£å†³æ–¹æ¡ˆ",
                'verify': "éªŒè¯è§£å†³æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§"
            }
        }

class FormalValidationEngine:
    """å½¢å¼åŒ–éªŒè¯å¼•æ“"""
    
    def __init__(self):
        self.validation_rules = {}
        self.logic_checkers = {}
        self._initialize_validators()
    
    def validate_reasoning(self, reasoning_chain: ReasoningChain) -> Dict[str, Any]:
        """éªŒè¯æ¨ç†é“¾"""
        validation_results = {
            'logical_consistency': self._check_logical_consistency(reasoning_chain),
            'evidence_coherence': self._check_evidence_coherence(reasoning_chain),
            'conclusion_validity': self._check_conclusion_validity(reasoning_chain),
            'completeness': self._check_completeness(reasoning_chain),
            'overall_score': 0.0
        }
        
        # è®¡ç®—æ€»åˆ†
        scores = [
            validation_results['logical_consistency']['score'],
            validation_results['evidence_coherence']['score'],
            validation_results['conclusion_validity']['score'],
            validation_results['completeness']['score']
        ]
        validation_results['overall_score'] = sum(scores) / len(scores)
        
        return validation_results
    
    def _check_logical_consistency(self, reasoning_chain: ReasoningChain) -> Dict[str, Any]:
        """æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§"""
        contradictions = []
        consistency_score = 1.0
        
        # æ£€æŸ¥æ­¥éª¤é—´çš„é€»è¾‘å…³ç³»
        for i, step in enumerate(reasoning_chain.steps[:-1]):
            next_step = reasoning_chain.steps[i + 1]
            
            # æ£€æŸ¥ç»“è®ºæ˜¯å¦ä¸ä¸‹ä¸€æ­¥çš„å‡è®¾ä¸€è‡´
            if step.conclusions:
                for conclusion in step.conclusions:
                    if conclusion in next_step.assumptions:
                        # ä¸€è‡´ï¼Œç»§ç»­
                        continue
                    elif self._is_contradiction(conclusion, next_step.assumptions):
                        contradictions.append(f"æ­¥éª¤ {i+1} å’Œ {i+2} ä¹‹é—´å­˜åœ¨é€»è¾‘çŸ›ç›¾")
                        consistency_score -= 0.2
        
        return {
            'score': max(0.0, consistency_score),
            'contradictions': contradictions,
            'status': 'consistent' if not contradictions else 'inconsistent'
        }
    
    def _check_evidence_coherence(self, reasoning_chain: ReasoningChain) -> Dict[str, Any]:
        """æ£€æŸ¥è¯æ®è¿è´¯æ€§"""
        evidence_score = 1.0
        missing_evidence = []
        
        for step in reasoning_chain.steps:
            if step.assumptions and not step.evidence:
                missing_evidence.append(f"æ­¥éª¤ {step.step_id} ç¼ºä¹æ”¯æŒè¯æ®")
                evidence_score -= 0.1
        
        return {
            'score': max(0.0, evidence_score),
            'missing_evidence': missing_evidence,
            'status': 'coherent' if not missing_evidence else 'needs_evidence'
        }
    
    def _check_conclusion_validity(self, reasoning_chain: ReasoningChain) -> Dict[str, Any]:
        """æ£€æŸ¥ç»“è®ºæœ‰æ•ˆæ€§"""
        if not reasoning_chain.steps:
            return {'score': 0.0, 'status': 'no_steps'}
        
        last_step = reasoning_chain.steps[-1]
        conclusion_score = 1.0
        
        # æ£€æŸ¥ç»“è®ºæ˜¯å¦å¾—åˆ°å‰é¢æ­¥éª¤çš„æ”¯æŒ
        if last_step.conclusions:
            for conclusion in last_step.conclusions:
                if not self._is_supported_by_evidence(conclusion, reasoning_chain.steps[:-1]):
                    conclusion_score -= 0.2
        
        return {
            'score': max(0.0, conclusion_score),
            'status': 'valid' if conclusion_score > 0.8 else 'questionable'
        }
    
    def _check_completeness(self, reasoning_chain: ReasoningChain) -> Dict[str, Any]:
        """æ£€æŸ¥å®Œæ•´æ€§"""
        completeness_score = 1.0
        missing_elements = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„é—®é¢˜å®šä¹‰
        if not reasoning_chain.problem_statement:
            missing_elements.append("ç¼ºå°‘æ˜ç¡®çš„é—®é¢˜å®šä¹‰")
            completeness_score -= 0.3
        
        # æ£€æŸ¥æ¨ç†æ­¥éª¤æ˜¯å¦å……åˆ†
        if len(reasoning_chain.steps) < 3:
            missing_elements.append("æ¨ç†æ­¥éª¤ä¸å……åˆ†")
            completeness_score -= 0.2
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆç»“è®º
        if not reasoning_chain.final_conclusion:
            missing_elements.append("ç¼ºå°‘æœ€ç»ˆç»“è®º")
            completeness_score -= 0.3
        
        return {
            'score': max(0.0, completeness_score),
            'missing_elements': missing_elements,
            'status': 'complete' if completeness_score > 0.8 else 'incomplete'
        }
    
    def _is_contradiction(self, statement: str, assumptions: List[str]) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨çŸ›ç›¾"""
        # ç®€åŒ–çš„çŸ›ç›¾æ£€æµ‹
        contradictory_pairs = [
            ('true', 'false'),
            ('yes', 'no'),
            ('enable', 'disable'),
            ('increase', 'decrease')
        ]
        
        for pair in contradictory_pairs:
            if pair[0] in statement.lower() and any(pair[1] in assumption.lower() for assumption in assumptions):
                return True
            if pair[1] in statement.lower() and any(pair[0] in assumption.lower() for assumption in assumptions):
                return True
        
        return False
    
    def _is_supported_by_evidence(self, conclusion: str, steps: List[ReasoningStep]) -> bool:
        """æ£€æŸ¥ç»“è®ºæ˜¯å¦å¾—åˆ°è¯æ®æ”¯æŒ"""
        conclusion_keywords = conclusion.lower().split()
        
        for step in steps:
            for evidence in step.evidence:
                evidence_keywords = evidence.lower().split()
                # ç®€åŒ–çš„è¯æ®æ”¯æŒæ£€æŸ¥
                if any(keyword in evidence_keywords for keyword in conclusion_keywords):
                    return True
        
        return False
    
    def _initialize_validators(self):
        """åˆå§‹åŒ–éªŒè¯å™¨"""
        self.validation_rules = {
            'logical_consistency': self._check_logical_consistency,
            'evidence_coherence': self._check_evidence_coherence,
            'conclusion_validity': self._check_conclusion_validity,
            'completeness': self._check_completeness
        }

class ARQReasoningEngineV2:
    """ARQæ¨ç†å¼•æ“V2.0"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # æ ¸å¿ƒç»„ä»¶
        self.compliance_rules = QuantumComplianceRules(self.config.get('rules_path'))
        self.reasoning_templates = AdvancedReasoningTemplates()
        self.validation_engine = FormalValidationEngine()
        
        # æ¨ç†å†å²
        self.reasoning_history = deque(maxlen=1000)
        self.performance_metrics = defaultdict(list)
        
        # é…ç½®
        self.default_compliance_level = ComplianceLevel(self.config.get('compliance_level', 'strict'))
        self.default_reasoning_mode = ReasoningMode(self.config.get('reasoning_mode', 'structured'))
        
        logger.info("ARQæ¨ç†å¼•æ“V2.0åˆå§‹åŒ–å®Œæˆ")
    
    def structured_reasoning(self, problem_statement: str, context: Dict[str, Any] = None,
                           reasoning_mode: Optional[ReasoningMode] = None,
                           compliance_level: Optional[ComplianceLevel] = None) -> ReasoningChain:
        """ç»“æ„åŒ–æ¨ç†è¿‡ç¨‹"""
        context = context or {}
        reasoning_mode = reasoning_mode or self.default_reasoning_mode
        compliance_level = compliance_level or self.default_compliance_level
        
        # ç”Ÿæˆæ¨ç†é“¾ID
        chain_id = hashlib.md5(f"{problem_statement}_{time.time()}".encode()).hexdigest()
        
        # è·å–æ¨ç†æ¨¡æ¿
        problem_type = self._classify_problem_type(problem_statement, context)
        template = self.reasoning_templates.get_template(reasoning_mode, problem_type)
        
        # æ‰§è¡Œæ¨ç†æ­¥éª¤
        steps = []
        current_context = context.copy()
        
        for step_name in template['steps']:
            step_prompt = template['prompts'].get(step_name, f"æ‰§è¡Œ{step_name}")
            step = self._execute_reasoning_step(
                step_name, step_prompt, problem_statement, current_context
            )
            steps.append(step)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            current_context.update({
                'last_step': step_name,
                'last_conclusions': step.conclusions,
                'accumulated_evidence': current_context.get('accumulated_evidence', []) + step.evidence
            })
        
        # ç”Ÿæˆæœ€ç»ˆç»“è®º
        final_conclusion = self._generate_final_conclusion(steps)
        
        # åˆ›å»ºæ¨ç†é“¾
        reasoning_chain = ReasoningChain(
            chain_id=chain_id,
            problem_statement=problem_statement,
            reasoning_mode=reasoning_mode,
            compliance_level=compliance_level,
            steps=steps,
            final_conclusion=final_conclusion,
            confidence_score=self._calculate_confidence_score(steps),
            compliance_score=self._calculate_compliance_score(steps, context)
        )
        
        # éªŒè¯æ¨ç†é“¾
        validation_results = self.validation_engine.validate_reasoning(reasoning_chain)
        reasoning_chain.validation_results = validation_results
        
        # è®°å½•æ¨ç†å†å²
        self.reasoning_history.append(reasoning_chain)
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        self._update_performance_metrics(reasoning_chain)
        
        return reasoning_chain
    
    def check_compliance(self, content: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ£€æŸ¥å†…å®¹åˆè§„æ€§"""
        return self.compliance_rules.check_compliance(content, context)
    
    def get_reasoning_insights(self, chain_id: str) -> Dict[str, Any]:
        """è·å–æ¨ç†æ´å¯Ÿ"""
        for chain in self.reasoning_history:
            if chain.chain_id == chain_id:
                return {
                    'chain_id': chain.chain_id,
                    'reasoning_mode': chain.reasoning_mode.value,
                    'compliance_level': chain.compliance_level.value,
                    'step_count': len(chain.steps),
                    'confidence_score': chain.confidence_score,
                    'compliance_score': chain.compliance_score,
                    'validation_summary': chain.validation_results,
                    'key_insights': self._extract_key_insights(chain)
                }
        
        return {'error': f'æœªæ‰¾åˆ°æ¨ç†é“¾: {chain_id}'}
    
    def optimize_reasoning_strategy(self, performance_history: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä¼˜åŒ–æ¨ç†ç­–ç•¥"""
        if not performance_history:
            return {'recommendations': ['æ”¶é›†æ›´å¤šæ€§èƒ½æ•°æ®']}
        
        # åˆ†ææ€§èƒ½è¶‹åŠ¿
        avg_confidence = sum(p.get('confidence_score', 0) for p in performance_history) / len(performance_history)
        avg_compliance = sum(p.get('compliance_score', 0) for p in performance_history) / len(performance_history)
        
        recommendations = []
        
        if avg_confidence < 0.8:
            recommendations.append("å»ºè®®å¢åŠ è¯æ®æ”¶é›†å’Œåˆ†ææ­¥éª¤")
        
        if avg_compliance < 0.9:
            recommendations.append("å»ºè®®åŠ å¼ºåˆè§„æ€§æ£€æŸ¥")
        
        # åˆ†ææœ€ä½³å®è·µ
        best_performances = sorted(performance_history, key=lambda x: x.get('overall_score', 0), reverse=True)[:5]
        common_patterns = self._identify_common_patterns(best_performances)
        
        return {
            'current_performance': {
                'avg_confidence': avg_confidence,
                'avg_compliance': avg_compliance
            },
            'recommendations': recommendations,
            'best_practices': common_patterns,
            'optimization_suggestions': self._generate_optimization_suggestions(common_patterns)
        }
    
    def _classify_problem_type(self, problem_statement: str, context: Dict[str, Any]) -> str:
        """åˆ†ç±»é—®é¢˜ç±»å‹"""
        statement_lower = problem_statement.lower()
        
        if any(keyword in statement_lower for keyword in ['design', 'create', 'build', 'develop']):
            return 'design'
        elif any(keyword in statement_lower for keyword in ['analyze', 'evaluate', 'assess', 'review']):
            return 'analytical'
        elif any(keyword in statement_lower for keyword in ['solve', 'fix', 'resolve', 'address']):
            return 'problem_solving'
        elif any(keyword in statement_lower for keyword in ['decide', 'choose', 'select', 'recommend']):
            return 'decision'
        else:
            return 'general'
    
    def _execute_reasoning_step(self, step_name: str, step_prompt: str, 
                              problem_statement: str, context: Dict[str, Any]) -> ReasoningStep:
        """æ‰§è¡Œæ¨ç†æ­¥éª¤"""
        step_id = hashlib.md5(f"{step_name}_{time.time()}".encode()).hexdigest()
        
        # æ¨¡æ‹Ÿæ¨ç†æ­¥éª¤æ‰§è¡Œï¼ˆå®é™…åº”ç”¨ä¸­ä¼šè°ƒç”¨LLMï¼‰
        step_content = f"æ­¥éª¤: {step_name}\næç¤º: {step_prompt}\né—®é¢˜: {problem_statement}"
        
        # åŸºäºæ­¥éª¤ç±»å‹ç”Ÿæˆç›¸åº”å†…å®¹
        if step_name == 'information_gathering':
            evidence = ["æ”¶é›†ç›¸å…³ä¿¡æ¯", "åˆ†ææ•°æ®æº", "éªŒè¯ä¿¡æ¯å‡†ç¡®æ€§"]
            assumptions = ["ä¿¡æ¯æ˜¯å¯é çš„", "æ•°æ®æ˜¯å®Œæ•´çš„"]
            conclusions = ["ä¿¡æ¯æ”¶é›†å®Œæˆ", "å·²è·å¾—è¶³å¤Ÿæ•°æ®"]
        elif step_name == 'hypothesis_formation':
            evidence = context.get('accumulated_evidence', [])
            assumptions = ["å‡è®¾åŸºäºå·²æœ‰ä¿¡æ¯", "å‡è®¾æ˜¯å¯éªŒè¯çš„"]
            conclusions = ["å½¢æˆåˆæ­¥å‡è®¾", "å‡è®¾éœ€è¦è¿›ä¸€æ­¥éªŒè¯"]
        else:
            evidence = []
            assumptions = []
            conclusions = [f"å®Œæˆ{step_name}æ­¥éª¤"]
        
        return ReasoningStep(
            step_id=step_id,
            step_type=step_name,
            content=step_content,
            confidence=0.8,
            evidence=evidence,
            assumptions=assumptions,
            conclusions=conclusions,
            next_steps=[]
        )
    
    def _generate_final_conclusion(self, steps: List[ReasoningStep]) -> str:
        """ç”Ÿæˆæœ€ç»ˆç»“è®º"""
        if not steps:
            return "æ— æ³•ç”Ÿæˆç»“è®ºï¼šç¼ºå°‘æ¨ç†æ­¥éª¤"
        
        last_step = steps[-1]
        if last_step.conclusions:
            return " ".join(last_step.conclusions)
        
        return "åŸºäºæ¨ç†åˆ†æå¾—å‡ºç»“è®º"
    
    def _calculate_confidence_score(self, steps: List[ReasoningStep]) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°"""
        if not steps:
            return 0.0
        
        total_confidence = sum(step.confidence for step in steps)
        return total_confidence / len(steps)
    
    def _calculate_compliance_score(self, steps: List[ReasoningStep], context: Dict[str, Any]) -> float:
        """è®¡ç®—åˆè§„åˆ†æ•°"""
        # æ£€æŸ¥æ‰€æœ‰æ­¥éª¤çš„åˆè§„æ€§
        total_score = 100.0
        
        for step in steps:
            compliance_result = self.compliance_rules.check_compliance(step.content, context)
            if not compliance_result['compliant']:
                total_score -= len(compliance_result['violations']) * 10
                total_score -= len(compliance_result['warnings']) * 5
        
        return max(0.0, total_score)
    
    def _extract_key_insights(self, reasoning_chain: ReasoningChain) -> List[str]:
        """æå–å…³é”®æ´å¯Ÿ"""
        insights = []
        
        # ä»æ¨ç†æ­¥éª¤ä¸­æå–æ´å¯Ÿ
        for step in reasoning_chain.steps:
            if step.conclusions:
                insights.extend(step.conclusions)
        
        # æ·»åŠ éªŒè¯ç»“æœæ´å¯Ÿ
        validation = reasoning_chain.validation_results
        if validation['overall_score'] > 0.9:
            insights.append("æ¨ç†è´¨é‡ä¼˜ç§€")
        elif validation['overall_score'] < 0.7:
            insights.append("æ¨ç†éœ€è¦æ”¹è¿›")
        
        return insights[:5]  # è¿”å›å‰5ä¸ªæ´å¯Ÿ
    
    def _identify_common_patterns(self, performances: List[Dict[str, Any]]) -> List[str]:
        """è¯†åˆ«å…±åŒæ¨¡å¼"""
        patterns = []
        
        # åˆ†ææˆåŠŸæ¡ˆä¾‹çš„å…±åŒç‰¹å¾
        high_score_cases = [p for p in performances if p.get('overall_score', 0) > 0.8]
        
        if high_score_cases:
            # ç»Ÿè®¡æ¨ç†æ¨¡å¼
            reasoning_modes = [p.get('reasoning_mode', 'structured') for p in high_score_cases]
            most_common_mode = max(set(reasoning_modes), key=reasoning_modes.count)
            patterns.append(f"æœ€å¸¸ç”¨çš„æ¨ç†æ¨¡å¼: {most_common_mode}")
            
            # ç»Ÿè®¡æ­¥éª¤æ•°é‡
            step_counts = [p.get('step_count', 0) for p in high_score_cases]
            avg_steps = sum(step_counts) / len(step_counts)
            patterns.append(f"å¹³å‡æ¨ç†æ­¥éª¤æ•°: {avg_steps:.1f}")
        
        return patterns
    
    def _generate_optimization_suggestions(self, patterns: List[str]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        for pattern in patterns:
            if "æ¨ç†æ¨¡å¼" in pattern:
                suggestions.append("ç»§ç»­ä½¿ç”¨æœ‰æ•ˆçš„æ¨ç†æ¨¡å¼")
            elif "æ­¥éª¤æ•°" in pattern:
                suggestions.append("ä¿æŒé€‚å½“çš„æ¨ç†è¯¦ç»†ç¨‹åº¦")
        
        # é€šç”¨ä¼˜åŒ–å»ºè®®
        suggestions.extend([
            "å®šæœŸæ›´æ–°åˆè§„è§„åˆ™",
            "æŒç»­ç›‘æ§æ¨ç†è´¨é‡",
            "æ”¶é›†ç”¨æˆ·åé¦ˆä»¥æ”¹è¿›æ¨ç†"
        ])
        
        return suggestions
    
    def _update_performance_metrics(self, reasoning_chain: ReasoningChain):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡"""
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'chain_id': reasoning_chain.chain_id,
            'reasoning_mode': reasoning_chain.reasoning_mode.value,
            'compliance_level': reasoning_chain.compliance_level.value,
            'step_count': len(reasoning_chain.steps),
            'confidence_score': reasoning_chain.confidence_score,
            'compliance_score': reasoning_chain.compliance_score,
            'overall_score': reasoning_chain.validation_results.get('overall_score', 0.0)
        }
        
        self.performance_metrics['reasoning_chains'].append(metrics)

# å…¨å±€ARQæ¨ç†å¼•æ“å®ä¾‹
_arq_engine_instance = None

def get_arq_engine(config: Dict[str, Any] = None) -> ARQReasoningEngineV2:
    """è·å–ARQæ¨ç†å¼•æ“å®ä¾‹"""
    global _arq_engine_instance
    if _arq_engine_instance is None:
        _arq_engine_instance = ARQReasoningEngineV2(config)
    return _arq_engine_instance

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import time
    
    def test_arq_engine():
        # åˆ›å»ºARQå¼•æ“
        config = {
            'compliance_level': 'strict',
            'reasoning_mode': 'structured'
        }
        
        arq_engine = get_arq_engine(config)
        
        # æµ‹è¯•ç»“æ„åŒ–æ¨ç†
        problem = "å¦‚ä½•è®¾è®¡ä¸€ä¸ªå®‰å…¨é«˜æ•ˆçš„ç”¨æˆ·è®¤è¯ç³»ç»Ÿï¼Ÿ"
        context = {
            'task_type': 'design',
            'security_requirements': ['authentication', 'authorization', 'encryption']
        }
        
        reasoning_chain = arq_engine.structured_reasoning(
            problem_statement=problem,
            context=context
        )
        
        print("æ¨ç†é“¾ç»“æœ:")
        print(f"é—®é¢˜: {reasoning_chain.problem_statement}")
        print(f"æ¨ç†æ¨¡å¼: {reasoning_chain.reasoning_mode.value}")
        print(f"åˆè§„çº§åˆ«: {reasoning_chain.compliance_level.value}")
        print(f"ç½®ä¿¡åº¦: {reasoning_chain.confidence_score:.2f}")
        print(f"åˆè§„åˆ†æ•°: {reasoning_chain.compliance_score:.2f}")
        print(f"æœ€ç»ˆç»“è®º: {reasoning_chain.final_conclusion}")
        
        print("\néªŒè¯ç»“æœ:")
        validation = reasoning_chain.validation_results
        for key, value in validation.items():
            if isinstance(value, dict) and 'score' in value:
                print(f"{key}: {value['score']:.2f} ({value['status']})")
        
        # æµ‹è¯•åˆè§„æ€§æ£€æŸ¥
        test_content = "è¿™æ˜¯ä¸€ä¸ªåŒ…å«ç”¨æˆ·å¯†ç å’Œä¿¡ç”¨å¡å·çš„å†…å®¹"
        compliance_result = arq_engine.check_compliance(test_content)
        
        print("\nåˆè§„æ€§æ£€æŸ¥ç»“æœ:")
        print(f"åˆè§„: {compliance_result['compliant']}")
        print(f"åˆè§„åˆ†æ•°: {compliance_result['compliance_score']}")
        
        if compliance_result['violations']:
            print("è¿è§„é¡¹:")
            for violation in compliance_result['violations']:
                print(f"  - {violation['rule_name']}: {violation['description']}")
    
    # è¿è¡Œæµ‹è¯•
    test_arq_engine()